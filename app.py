import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Asumiendo que tu DataFrame se llama 'df' y ya est√° cargado
# df = pd.read_csv('telco_customer_churn.csv')
## url = 'https://raw.githubusercontent.com/Sarthakrshetty/Telco-Customer-Churn-Analysis/refs/heads/main/customer%20churn.csv'
df = pd.read_csv(r'C:\Users\REINALDO\Videos\Proyecto\customer_churn.csv')

# --- 1. An√°lisis de la Variable Objetivo (Churn) ---

print("--- 1. An√°lisis del Desbalance (Variable 'Churn') ---")

# Calculamos el n√∫mero de clientes que abandonaron y los que no
churn_counts = df['Churn'].value_counts()
churn_percent = df['Churn'].value_counts(normalize=True) * 100

print("\nConteo de Clientes:")
print(churn_counts)
print("\nPorcentaje de Churn:")
print(round(churn_percent, 2), '%')

# Visualizaci√≥n del Desbalance
plt.figure(figsize=(6, 4))
sns.barplot(x=churn_counts.index, y=churn_counts.values)
plt.title('Distribuci√≥n de Clientes con y sin Churn')
plt.xlabel('Churn')
plt.ylabel('Conteo de Clientes')
plt.show()

print("Observaci√≥n Clave: El dataset est√° desbalanceado. La tasa de abandono es del", 
      round(churn_percent['Yes'], 2), "%")

# --- 2. An√°lisis de la Variable Num√©rica Clave: Antig√ºedad (Tenure) ---

print("\n--- 2. An√°lisis de la Antig√ºedad (Tenure) vs. Churn ---")

# Gr√°fico de Caja (Box Plot) para comparar la distribuci√≥n de Tenure
plt.figure(figsize=(8, 6))
sns.boxplot(x='Churn', y='tenure', data=df)
plt.title('Distribuci√≥n de Antig√ºedad (Tenure) por Clase de Churn')
plt.xlabel('Churn (Abandono)')
plt.ylabel('Antig√ºedad (Meses)')
plt.show()

# Gr√°fico de Histograma para ver la distribuci√≥n completa
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='tenure', hue='Churn', multiple='stack', bins=30, kde=True)
plt.title('Histograma de Antig√ºedad por Churn')
plt.xlabel('Antig√ºedad (Meses)')
plt.ylabel('Frecuencia')
plt.show()

# Calcular la Antig√ºedad Promedio (para el README)
tenure_avg = df.groupby('Churn')['tenure'].mean().round(2)
print("\nAntig√ºedad (Tenure) Promedio:")
print(tenure_avg)

print("\nObservaci√≥n Clave: Los clientes que abandonan ('Yes') tienen una antig√ºedad promedio de:", 
      tenure_avg['Yes'], "meses, significativamente menor a los que se quedan.")

# Continuando con el DataFrame 'df'

print("--- 3. An√°lisis de Variables Categ√≥ricas Clave vs. Churn ---")

# Lista de variables categ√≥ricas a analizar
categorias_clave = ['Contract', 'OnlineSecurity', 'PaymentMethod']

# Funci√≥n para calcular y visualizar la tasa de Churn por categor√≠a
def analizar_categoria(df, columna):
    # Calcular el porcentaje de Churn ('Yes') para cada categor√≠a
    churn_rate = df.groupby(columna)['Churn'].value_counts(normalize=True).mul(100).unstack()['Yes'].sort_values(ascending=False)
    
    print(f"\nTasas de Churn por {columna}:")
    print(round(churn_rate, 2), '%')

    # Visualizaci√≥n (Gr√°fico de barras apiladas)
    plt.figure(figsize=(8, 5))
    df_plot = df.groupby(columna)['Churn'].value_counts(normalize=True).mul(100).unstack()
    df_plot.plot(kind='bar', stacked=True, figsize=(10, 6))
    plt.title(f'Distribuci√≥n de Churn por {columna}')
    plt.ylabel('Porcentaje')
    plt.xticks(rotation=45, ha='right')
    plt.legend(title='Churn')
    plt.show()

# Ejecutar el an√°lisis para cada categor√≠a
for col in categorias_clave:
    analizar_categoria(df, col)
    

import numpy as np

# Convertir 'TotalCharges' a num√©rico. El argumento 'coerce' convierte los errores (como strings vac√≠os) en NaN.
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Verificamos cu√°ntos NaN hay (deber√≠an ser muy pocos)
print("Valores NaN en TotalCharges:", df['TotalCharges'].isnull().sum())

# La mejor forma de imputar es con la mediana, pero dado que son clientes muy nuevos (tenure=0),
# lo m√°s seguro es imputarlos con 0, ya que no han generado cargos totales.

# Si decides imputar con 0 (basado en el contexto de churn dataset)
df['TotalCharges'].fillna(0, inplace=True)

print("Verificaci√≥n de valores faltantes despu√©s de la imputaci√≥n:", df['TotalCharges'].isnull().sum())





# Variables binarias que necesitan ser convertidas a 0 y 1
binary_cols = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity',
               'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 
               'StreamingMovies', 'PaperlessBilling', 'Churn']

for col in binary_cols:
    # Mapeo simple de 'Yes' a 1 y 'No' a 0, asumiendo que el 'No internet service'
    # y 'No phone service' se tratar√°n en el One-Hot Encoding si existen o se convierten a 'No'.
    # Para el Target 'Churn', 'Yes' es la clase positiva (1).
    if col == 'Churn':
        df[col] = df[col].map({'Yes': 1, 'No': 0})
    else:
        df[col] = df[col].replace({'Yes': 1, 'No': 0, 'No internet service': 0, 'No phone service': 0})


# Variables multi-categ√≥ricas
categorical_cols = ['gender', 'InternetService', 'Contract', 'PaymentMethod']

# Aplicar One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True) 
# drop_first=True elimina una columna de cada grupo para evitar multicolinealidad.
# Por ejemplo, si tienes 'Gender_Female' y 'Gender_Male', solo necesitas una columna.

# Eliminamos la columna original 'customerID' ya que no es √∫til para el modelo
df_final = df_encoded.drop(columns=['customerID'])

print("\nDimensiones del DataFrame despu√©s de la codificaci√≥n:", df_final.shape)
print("Primeras 5 filas del DataFrame final (muestra de codificaci√≥n):")
print(df_final.head())


# 1. Separar caracter√≠sticas (X) y objetivo (y)
X = df_final.drop('Churn', axis=1) # Todas las columnas excepto 'Churn'
y = df_final['Churn']              # Solo la columna 'Churn'



from sklearn.model_selection import train_test_split

# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)
# Usamos stratify=y para asegurar que ambos conjuntos tengan la misma proporci√≥n de Churn
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("\nDimensiones de los conjuntos:")
print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
print(f"X_test: {X_test.shape}, y_test: {y_test.shape}")


from sklearn.preprocessing import StandardScaler

# Identificar las columnas a escalar (las num√©ricas originales)
# 'SeniorCitizen' es binaria (0/1), por lo que no necesita escalado.
cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Inicializar el escalador
scaler = StandardScaler()

# Ajustar (fit) el escalador solo en el conjunto de ENTRENAMIENTO y transformarlo
X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])

# Solo transformar (transform) el conjunto de PRUEBA (usando la media y desviaci√≥n est√°ndar del entrenamiento)
X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])

print("\nVerificaci√≥n de datos escalados (X_train):")
print(X_train[cols_to_scale].head())


import xgboost as xgb
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings("ignore")

print("--- 1. Aplicando SMOTE y Entrenando XGBoost ---")

# Debido al desbalance de clases (visto en el EDA), aplicamos SMOTE solo al conjunto de entrenamiento.
# Esto genera datos sint√©ticos de la clase minoritaria ('Churn=Yes').
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print(f"\nProporci√≥n Churn en datos originales: {y_train.sum() / len(y_train) * 100:.2f}%")
print(f"Proporci√≥n Churn en datos con SMOTE: {y_train_smote.sum() / len(y_train_smote) * 100:.2f}%")

# Inicializar y entrenar el clasificador XGBoost
# Nota: La estructura de XGBoost compensa un poco el desbalance, pero el SMOTE ayuda mucho en este caso.
xgb_model = xgb.XGBClassifier(
    objective='binary:logistic', # Clasificaci√≥n binaria
    eval_metric='logloss',       # M√©trica para evaluaci√≥n interna
    use_label_encoder=False,     # Pr√°ctica recomendada por XGBoost
    random_state=42
)

# Entrenar el modelo con los datos balanceados
xgb_model.fit(X_train_smote, y_train_smote)
print("\nModelo XGBoost entrenado con √©xito.")



# Realizar predicciones en el conjunto de prueba
y_pred = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)[:, 1] # Probabilidades para ROC AUC

print("\n--- 2. Evaluaci√≥n del Modelo en Conjunto de Prueba ---")

# Informe de Clasificaci√≥n
print("\nInforme de Clasificaci√≥n:")
print(classification_report(y_test, y_pred))

# Matriz de Confusi√≥n
cm = confusion_matrix(y_test, y_pred)
print("Matriz de Confusi√≥n:")
print(cm)

# ROC AUC Score (Mide qu√© tan bien el modelo distingue entre las clases)
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"\nROC AUC Score: {roc_auc:.4f}")

# Explicaci√≥n de las m√©tricas
print("\nAn√°lisis de M√©tricas:")
print("üéØ El 'Recall' para la clase 1 (Churn=Yes) es la m√©trica m√°s cr√≠tica en negocio, ya que mide cu√°ntos clientes en riesgo REAL el modelo logr√≥ capturar.")
print("‚≠ê El F1-Score ofrece una visi√≥n balanceada de la Precisi√≥n y el Recall.")




import shap

print("\n--- 3. Explicabilidad con SHAP ---")

# 1. Crear el 'explainer' de SHAP (usa TreeExplainer para modelos basados en √°rboles)
explainer = shap.TreeExplainer(xgb_model)

# 2. Calcular los valores SHAP para el conjunto de prueba
shap_values = explainer.shap_values(X_test)

# 3. Visualizar la importancia global de las caracter√≠sticas (Summary Plot)
print("\nGr√°fico de Importancia Global (Summary Plot):")
# Cada punto es una predicci√≥n de un cliente. 
# El color indica el valor de la caracter√≠stica (rojo = alto, azul = bajo).
# El eje X es el impacto en la predicci√≥n.
shap.summary_plot(shap_values, X_test)
# 

print("Interpretaci√≥n Global: El gr√°fico anterior muestra que los factores como el 'Tipo de Contrato (mes a mes)', la 'Antig√ºedad (tenure)' y el 'Servicio de Internet (Fibra √≥ptica)' son los principales impulsores del Churn.")



# --- 4. Selecci√≥n del Cliente de Alto Riesgo ---

# 1. Obtenemos las probabilidades predichas en el conjunto de prueba
y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]

# 2. Encontramos la POSICI√ìN (no el √≠ndice) del primer cliente con probabilidad > 0.9
# Usamos np.where para encontrar la posici√≥n en el array
high_risk_position_in_test = np.where(y_pred_proba > 0.9)[0].tolist()[0] 
# Si el modelo no tiene predicciones > 0.9, necesitar√°s ajustar este umbral.

# 3. Accedemos a los datos del cliente de PRUEBA usando .iloc (posici√≥n)
customer_data = X_test.iloc[high_risk_position_in_test]
# customer_data ser√° la fila de entrada para la explicaci√≥n

print(f"\nExplicaci√≥n Local para Cliente de Alto Riesgo (Posici√≥n en X_test: {high_risk_position_in_test}):")
print("Caracter√≠sticas del cliente (Primeras 10):")
print(customer_data.head(10)) 

# --- 5. Visualizaci√≥n del Gr√°fico de Cascada Corregida ---

# 1. Creamos el objeto EXPLANATION completo para el conjunto de prueba.
# Esto solo se hace una vez, pero lo repetimos aqu√≠ para asegurarnos de que el 'explainer' est√© en el contexto.
explainer_output = explainer(X_test)

# 2. Usamos el objeto de EXPLICACI√ìN y accedemos a la posici√≥n espec√≠fica.
# Al pasar el objeto completo explainer_output[posici√≥n], se pasa la base value, los SHAP values,
# y los valores de las caracter√≠sticas, tal como lo requiere la funci√≥n waterfall.
shap.plots.waterfall(
    explainer_output[high_risk_position_in_test],
    max_display=10,
    show=True
)

print("\nInterpretaci√≥n Local: El gr√°fico de cascada muestra c√≥mo cada caracter√≠stica espec√≠fica de este cliente (en rojo) impuls√≥ la predicci√≥n hacia la clase 'Churn=Yes'.")


import joblib
# Despu√©s de entrenar:
joblib.dump(xgb_model, 'xgb_model.pkl')
joblib.dump(scaler, 'scaler.pkl')


import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
import io
import streamlit.components.v1 as components


# ----------------------------------------------------
# 0. FUNCI√ìN SHAP UNIVERSAL (HTML + MATPLOTLIB)
# ----------------------------------------------------
def st_shap(plot, height=250):
    """
    Renderiza cualquier gr√°fico SHAP en Streamlit.
    - Si es HTML (ej. force_plot) ‚Üí lo incrusta con components.html
    - Si es Matplotlib (ej. waterfall) ‚Üí lo convierte a imagen PNG
    """
    # Caso 1: Gr√°fico HTML (force_plot)
    if hasattr(plot, "html"):
        shap_html = f"<head>{shap.getjs()}</head><body>{plot.html()}</body>"
        components.html(shap_html, height=height)
        return

    # Caso 2: Gr√°fico Matplotlib (waterfall, beeswarm, bar, etc.)
    buf = io.BytesIO()
    plt.savefig(buf, format="png", bbox_inches="tight")
    buf.seek(0)
    st.image(buf)
    plt.clf()



# ----------------------------------------------------
# 1. CONFIGURACI√ìN E IMPORTACI√ìN DE MODELOS
# ----------------------------------------------------
st.set_page_config(page_title="Predicci√≥n de Churn", layout="wide")

try:
    model = joblib.load('xgb_model.pkl')
    scaler = joblib.load('scaler.pkl')
    feature_names = model.get_booster().feature_names
except FileNotFoundError:
    st.error("‚ùå Error: Archivos xgb_model.pkl o scaler.pkl no encontrados.")
    st.stop()



# ----------------------------------------------------
# 2. INTERFAZ DE USUARIO
# ----------------------------------------------------
st.title("üë®‚Äçüíª Predictor de Abandono de Clientes (Churn)")
st.subheader("Herramienta basada en XGBoost y an√°lisis SHAP.")

with st.sidebar:
    st.header("Caracter√≠sticas del Cliente")

    tenure = st.slider("Antig√ºedad (Meses)", 0, 72, 24)
    monthly_charges = st.number_input("Cargos Mensuales ($", 18.25, 118.75, 50.0)

    contract = st.selectbox("Tipo de Contrato", ['Month-to-month', 'One year', 'Two year'])
    internet_service = st.selectbox("Servicio de Internet", ['Fiber optic', 'DSL', 'No'])
    security = st.selectbox("Seguridad en L√≠nea", ['Yes', 'No', 'No internet service'])

predict_button = st.button("üöÄ Predecir y Explicar el Churn")



# ----------------------------------------------------
# 3. L√ìGICA DE PREDICCI√ìN
# ----------------------------------------------------
if predict_button:

    # --- 3.1 Crear vector vac√≠o con columnas del modelo ---
    input_data = pd.Series(0, index=feature_names)

    # --- 3.2 Asignar valores num√©ricos ---
    input_data['tenure'] = tenure
    input_data['MonthlyCharges'] = monthly_charges

    if 'TotalCharges' in input_data:
        input_data['TotalCharges'] = tenure * monthly_charges

    # --- 3.3 One-Hot Encoding manual seg√∫n las columnas existentes ---
    if contract == 'One year':
        input_data['Contract_One year'] = 1
    elif contract == 'Two year':
        input_data['Contract_Two year'] = 1

    if internet_service == 'Fiber optic':
        input_data['InternetService_Fiber optic'] = 1
    elif internet_service == 'No':
        input_data['InternetService_No'] = 1

    # Seguridad en l√≠nea
    if security == 'Yes':
        if 'OnlineSecurity_Yes' in input_data:
            input_data['OnlineSecurity_Yes'] = 1
        elif 'OnlineSecurity' in input_data:
            input_data['OnlineSecurity'] = 1
    elif security == 'No internet service':
        if 'OnlineSecurity_No internet service' in input_data:
            input_data['OnlineSecurity_No internet service'] = 1

    # --- 3.4 Crear DataFrame final ---
    X_input = pd.DataFrame([input_data.values], columns=feature_names)

    # --- 3.5 Escalar variables num√©ricas ---
    cols_to_scale = [col for col in ['tenure', 'MonthlyCharges', 'TotalCharges'] if col in X_input.columns]
    if cols_to_scale:
        X_input[cols_to_scale] = scaler.transform(X_input[cols_to_scale])

    # --- 3.6 Predicci√≥n ---
    prediction_proba = model.predict_proba(X_input)[:, 1][0]

    st.markdown("---")

    col1, col2 = st.columns(2)

    with col1:
        if prediction_proba >= 0.5:
            st.error("‚ö†Ô∏è **ALTO RIESGO DE ABANDONO (CHURN)**")
        else:
            st.success("‚úÖ **BAJO RIESGO DE ABANDONO (CHURN)**")

    with col2:
        st.metric("Probabilidad estimada", f"{prediction_proba*100:.2f}%")



    # ----------------------------------------------------
    # 4. EXPLICACI√ìN SHAP
    # ----------------------------------------------------
    st.subheader("üß† Explicaci√≥n de la Predicci√≥n (SHAP)")

    explainer = shap.TreeExplainer(model)
    shap_values = explainer(X_input)

    plt.figure(figsize=(6, 4)) # Ajustar el tama√±o del gr√°fico
    shap_plot = shap.plots.waterfall(
        shap_values[0],
        max_display=10,
        show=False
    )

    st_shap(shap_plot, height=250)

    st.info("El gr√°fico explica c√≥mo cada caracter√≠stica aument√≥ (rojo) o disminuy√≥ (azul) el riesgo de abandono.")


